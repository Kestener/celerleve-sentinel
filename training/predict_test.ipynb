{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained YOLO model (recommended for training)\n",
    "model = YOLO('../data/models/YOLOv8_Landslide_WorkingV1_best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ehwaz/Documents/Spiced/celerleve-sentinel/data/satellite_images_train_v1/satellite_predict_test_y.jpg: 416x640 62 landslide-paths, 175.6ms\n",
      "Speed: 0.5ms preprocess, 175.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Perform object detection on an image using the model\n",
    "results = model.predict('../data/satellite_images_train_v1/satellite_predict_test_y.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1639e+01, 2.0912e+02, 2.6829e+01, 2.2895e+02, 5.3778e-01, 0.0000e+00],\n",
      "        [5.3309e+01, 1.7367e+02, 7.0842e+01, 1.9446e+02, 5.3384e-01, 0.0000e+00],\n",
      "        [7.4770e+01, 1.8004e+00, 1.0700e+02, 3.1735e+01, 4.9095e-01, 0.0000e+00],\n",
      "        [4.5799e+01, 2.1066e+02, 5.8020e+01, 2.3525e+02, 4.8515e-01, 0.0000e+00],\n",
      "        [2.0190e+02, 1.5187e+02, 2.1673e+02, 1.7911e+02, 4.8260e-01, 0.0000e+00],\n",
      "        [1.3638e+02, 8.8674e+01, 1.5462e+02, 1.1311e+02, 4.7440e-01, 0.0000e+00],\n",
      "        [1.1884e+01, 3.5129e+01, 2.8259e+01, 6.4689e+01, 4.6527e-01, 0.0000e+00],\n",
      "        [2.9660e+02, 6.7579e+00, 3.1573e+02, 4.1105e+01, 4.5799e-01, 0.0000e+00],\n",
      "        [2.6735e+01, 5.6895e+01, 4.3194e+01, 9.1674e+01, 4.4976e-01, 0.0000e+00],\n",
      "        [1.3818e+02, 4.2038e+01, 1.7991e+02, 6.1772e+01, 4.4942e-01, 0.0000e+00],\n",
      "        [1.3141e+02, 6.7029e+01, 1.6073e+02, 8.2808e+01, 4.4369e-01, 0.0000e+00],\n",
      "        [6.4411e+02, 3.4599e+02, 6.5520e+02, 3.6229e+02, 4.4324e-01, 0.0000e+00],\n",
      "        [2.4600e+02, 7.7863e+01, 2.7043e+02, 9.9691e+01, 4.4081e-01, 0.0000e+00],\n",
      "        [2.6888e+02, 7.6591e+01, 2.8335e+02, 9.0225e+01, 4.2389e-01, 0.0000e+00],\n",
      "        [2.3201e+02, 1.6834e+02, 2.4507e+02, 1.9049e+02, 4.2128e-01, 0.0000e+00],\n",
      "        [1.9668e+02, 5.8634e+01, 2.1591e+02, 8.0906e+01, 4.1324e-01, 0.0000e+00],\n",
      "        [1.1016e+02, 1.0566e+02, 1.4154e+02, 1.2216e+02, 4.0239e-01, 0.0000e+00],\n",
      "        [2.0334e+02, 1.5079e+02, 2.1897e+02, 1.7673e+02, 3.9767e-01, 0.0000e+00],\n",
      "        [1.3394e+02, 1.8143e+02, 1.4773e+02, 1.9266e+02, 3.9666e-01, 0.0000e+00],\n",
      "        [3.5746e+02, 1.8406e+02, 3.7012e+02, 1.9692e+02, 3.9412e-01, 0.0000e+00],\n",
      "        [1.4375e+02, 1.9674e+02, 1.5659e+02, 2.2918e+02, 3.9011e-01, 0.0000e+00],\n",
      "        [2.7234e+02, 1.4109e+02, 2.8349e+02, 1.5945e+02, 3.8946e-01, 0.0000e+00],\n",
      "        [3.2964e+02, 3.8300e+01, 3.5530e+02, 5.4455e+01, 3.8046e-01, 0.0000e+00],\n",
      "        [7.4192e+01, 1.9341e+02, 8.6594e+01, 2.3102e+02, 3.6332e-01, 0.0000e+00],\n",
      "        [9.8842e+01, 1.8539e+02, 1.1239e+02, 2.1254e+02, 3.6128e-01, 0.0000e+00],\n",
      "        [2.5372e+02, 1.6313e+02, 2.7720e+02, 1.8489e+02, 3.6115e-01, 0.0000e+00],\n",
      "        [1.3797e+02, 1.3106e+02, 1.5064e+02, 1.7082e+02, 3.5959e-01, 0.0000e+00],\n",
      "        [1.6819e+02, 1.7560e+02, 1.9304e+02, 2.1018e+02, 3.5660e-01, 0.0000e+00],\n",
      "        [3.3419e+02, 1.6422e+02, 3.4790e+02, 1.8387e+02, 3.4856e-01, 0.0000e+00],\n",
      "        [2.8420e+02, 3.5207e+02, 2.9954e+02, 3.6341e+02, 3.3915e-01, 0.0000e+00],\n",
      "        [1.9599e+02, 1.7486e+02, 2.0787e+02, 1.9081e+02, 3.3001e-01, 0.0000e+00],\n",
      "        [3.0179e+02, 1.1274e+02, 3.2707e+02, 1.2862e+02, 3.2958e-01, 0.0000e+00],\n",
      "        [3.4980e+02, 1.6080e+02, 3.6729e+02, 1.8048e+02, 3.2689e-01, 0.0000e+00],\n",
      "        [1.8115e+02, 4.1139e+01, 1.9670e+02, 5.4898e+01, 3.2090e-01, 0.0000e+00],\n",
      "        [3.2519e+02, 5.0297e+01, 3.4051e+02, 6.9196e+01, 3.1574e-01, 0.0000e+00],\n",
      "        [7.6209e+01, 1.9400e+02, 8.8892e+01, 2.3124e+02, 3.1465e-01, 0.0000e+00],\n",
      "        [3.2772e+02, 7.1679e+01, 3.6501e+02, 8.9500e+01, 3.1441e-01, 0.0000e+00],\n",
      "        [1.1810e+02, 1.8129e+02, 1.2791e+02, 2.0524e+02, 3.1413e-01, 0.0000e+00],\n",
      "        [4.0180e+01, 5.8830e+00, 5.5423e+01, 3.5962e+01, 3.1058e-01, 0.0000e+00],\n",
      "        [1.7099e+02, 7.7892e+01, 1.8957e+02, 9.3412e+01, 3.0909e-01, 0.0000e+00],\n",
      "        [3.1479e+02, 1.2155e+02, 3.4743e+02, 1.4105e+02, 3.0806e-01, 0.0000e+00],\n",
      "        [3.5461e+01, 8.0045e+00, 5.6421e+01, 4.0560e+01, 3.0454e-01, 0.0000e+00],\n",
      "        [2.1571e+02, 1.0360e+02, 2.3748e+02, 1.3422e+02, 3.0220e-01, 0.0000e+00],\n",
      "        [7.8623e+01, 1.5830e+02, 8.8986e+01, 1.7811e+02, 2.9922e-01, 0.0000e+00],\n",
      "        [1.1198e+02, 1.0517e+02, 1.4964e+02, 1.2925e+02, 2.9057e-01, 0.0000e+00],\n",
      "        [1.5389e+02, 1.8780e+02, 1.7175e+02, 2.0211e+02, 2.8949e-01, 0.0000e+00],\n",
      "        [3.5330e+01, 1.9996e+02, 4.7424e+01, 2.1758e+02, 2.8718e-01, 0.0000e+00],\n",
      "        [1.6380e+01, 2.3416e+02, 4.1218e+01, 2.5513e+02, 2.8582e-01, 0.0000e+00],\n",
      "        [2.4709e+02, 1.1964e+02, 2.6409e+02, 1.3412e+02, 2.8482e-01, 0.0000e+00],\n",
      "        [1.2250e+02, 1.8050e+02, 1.3673e+02, 2.0707e+02, 2.8382e-01, 0.0000e+00],\n",
      "        [3.6393e+02, 1.9645e+02, 3.7932e+02, 2.0837e+02, 2.8059e-01, 0.0000e+00],\n",
      "        [1.9392e+02, 1.0881e+02, 2.1102e+02, 1.3964e+02, 2.7131e-01, 0.0000e+00],\n",
      "        [1.5910e+02, 2.2717e+02, 1.7203e+02, 2.3832e+02, 2.6811e-01, 0.0000e+00],\n",
      "        [6.4181e+02, 3.4720e+02, 6.5443e+02, 3.6460e+02, 2.6807e-01, 0.0000e+00],\n",
      "        [1.6330e+02, 1.5132e+02, 1.7985e+02, 1.7253e+02, 2.6656e-01, 0.0000e+00],\n",
      "        [2.4763e+02, 9.8330e+01, 2.6105e+02, 1.2256e+02, 2.6622e-01, 0.0000e+00],\n",
      "        [1.2055e+02, 1.8019e+02, 1.3566e+02, 2.0264e+02, 2.6490e-01, 0.0000e+00],\n",
      "        [2.6508e+02, 1.0210e+02, 2.7871e+02, 1.2403e+02, 2.6401e-01, 0.0000e+00],\n",
      "        [1.6312e+02, 8.1744e+01, 1.7308e+02, 9.7257e+01, 2.6386e-01, 0.0000e+00],\n",
      "        [1.1455e+02, 1.5344e+02, 1.2565e+02, 1.7694e+02, 2.6065e-01, 0.0000e+00],\n",
      "        [1.9627e+02, 1.2942e+02, 2.1399e+02, 1.4464e+02, 2.5988e-01, 0.0000e+00],\n",
      "        [1.7263e+02, 1.0712e+02, 1.8879e+02, 1.2501e+02, 2.5724e-01, 0.0000e+00],\n",
      "        [1.7692e+02, 1.2245e+02, 1.9294e+02, 1.4279e+02, 2.5717e-01, 0.0000e+00],\n",
      "        [6.0300e+02, 4.0258e+02, 6.1675e+02, 4.1695e+02, 2.5672e-01, 0.0000e+00],\n",
      "        [4.5256e+01, 1.9859e+02, 6.0841e+01, 2.1115e+02, 2.5341e-01, 0.0000e+00],\n",
      "        [1.0821e+02, 1.2773e+02, 1.2335e+02, 1.4832e+02, 2.5301e-01, 0.0000e+00],\n",
      "        [1.8815e+02, 5.9539e+01, 1.9839e+02, 7.7542e+01, 2.5030e-01, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "print(results[0].boxes.boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_label(image, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n",
    "  lw = max(round(sum(image.shape) / 2 * 0.003), 2)\n",
    "  p1, p2 = (int(box[0]), int(box[1])), (int(box[2]), int(box[3]))\n",
    "  cv2.rectangle(image, p1, p2, color, thickness=lw, lineType=cv2.LINE_AA)\n",
    "  if label:\n",
    "    tf = max(lw - 1, 1)  # font thickness\n",
    "    w, h = cv2.getTextSize(label, 0, fontScale=lw / 3, thickness=tf)[0]  # text width, height\n",
    "    outside = p1[1] - h >= 3\n",
    "    p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
    "    cv2.rectangle(image, p1, p2, color, -1, cv2.LINE_AA)  # filled\n",
    "    cv2.putText(image,\n",
    "                label, (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),\n",
    "                0,\n",
    "                lw / 3,\n",
    "                txt_color,\n",
    "                thickness=tf,\n",
    "                lineType=cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bboxes(image, boxes, labels=[], colors=[], score=True, conf=None):\n",
    "  #Define COCO Labels\n",
    "  if labels == []:\n",
    "    labels = {0: u'__background__', 1: u'person', 2: u'bicycle',3: u'car', 4: u'motorcycle', 5: u'airplane', 6: u'bus', 7: u'train', 8: u'truck', 9: u'boat', 10: u'traffic light', 11: u'fire hydrant', 12: u'stop sign', 13: u'parking meter', 14: u'bench', 15: u'bird', 16: u'cat', 17: u'dog', 18: u'horse', 19: u'sheep', 20: u'cow', 21: u'elephant', 22: u'bear', 23: u'zebra', 24: u'giraffe', 25: u'backpack', 26: u'umbrella', 27: u'handbag', 28: u'tie', 29: u'suitcase', 30: u'frisbee', 31: u'skis', 32: u'snowboard', 33: u'sports ball', 34: u'kite', 35: u'baseball bat', 36: u'baseball glove', 37: u'skateboard', 38: u'surfboard', 39: u'tennis racket', 40: u'bottle', 41: u'wine glass', 42: u'cup', 43: u'fork', 44: u'knife', 45: u'spoon', 46: u'bowl', 47: u'banana', 48: u'apple', 49: u'sandwich', 50: u'orange', 51: u'broccoli', 52: u'carrot', 53: u'hot dog', 54: u'pizza', 55: u'donut', 56: u'cake', 57: u'chair', 58: u'couch', 59: u'potted plant', 60: u'bed', 61: u'dining table', 62: u'toilet', 63: u'tv', 64: u'laptop', 65: u'mouse', 66: u'remote', 67: u'keyboard', 68: u'cell phone', 69: u'microwave', 70: u'oven', 71: u'toaster', 72: u'sink', 73: u'refrigerator', 74: u'book', 75: u'clock', 76: u'vase', 77: u'scissors', 78: u'teddy bear', 79: u'hair drier', 80: u'toothbrush'}\n",
    "  #Define colors\n",
    "  if colors == []:\n",
    "    #colors = [(6, 112, 83), (253, 246, 160), (40, 132, 70), (205, 97, 162), (149, 196, 30), (106, 19, 161), (127, 175, 225), (115, 133, 176), (83, 156, 8), (182, 29, 77), (180, 11, 251), (31, 12, 123), (23, 6, 115), (167, 34, 31), (176, 216, 69), (110, 229, 222), (72, 183, 159), (90, 168, 209), (195, 4, 209), (135, 236, 21), (62, 209, 199), (87, 1, 70), (75, 40, 168), (121, 90, 126), (11, 86, 86), (40, 218, 53), (234, 76, 20), (129, 174, 192), (13, 18, 254), (45, 183, 149), (77, 234, 120), (182, 83, 207), (172, 138, 252), (201, 7, 159), (147, 240, 17), (134, 19, 233), (202, 61, 206), (177, 253, 26), (10, 139, 17), (130, 148, 106), (174, 197, 128), (106, 59, 168), (124, 180, 83), (78, 169, 4), (26, 79, 176), (185, 149, 150), (165, 253, 206), (220, 87, 0), (72, 22, 226), (64, 174, 4), (245, 131, 96), (35, 217, 142), (89, 86, 32), (80, 56, 196), (222, 136, 159), (145, 6, 219), (143, 132, 162), (175, 97, 221), (72, 3, 79), (196, 184, 237), (18, 210, 116), (8, 185, 81), (99, 181, 254), (9, 127, 123), (140, 94, 215), (39, 229, 121), (230, 51, 96), (84, 225, 33), (218, 202, 139), (129, 223, 182), (167, 46, 157), (15, 252, 5), (128, 103, 203), (197, 223, 199), (19, 238, 181), (64, 142, 167), (12, 203, 242), (69, 21, 41), (177, 184, 2), (35, 97, 56), (241, 22, 161)]\n",
    "    colors = [(89, 161, 197),(67, 161, 255),(19, 222, 24),(186, 55, 2),(167, 146, 11),(190, 76, 98),(130, 172, 179),(115, 209, 128),(204, 79, 135),(136, 126, 185),(209, 213, 45),(44, 52, 10),(101, 158, 121),(179, 124, 12),(25, 33, 189),(45, 115, 11),(73, 197, 184),(62, 225, 221),(32, 46, 52),(20, 165, 16),(54, 15, 57),(12, 150, 9),(10, 46, 99),(94, 89, 46),(48, 37, 106),(42, 10, 96),(7, 164, 128),(98, 213, 120),(40, 5, 219),(54, 25, 150),(251, 74, 172),(0, 236, 196),(21, 104, 190),(226, 74, 232),(120, 67, 25),(191, 106, 197),(8, 15, 134),(21, 2, 1),(142, 63, 109),(133, 148, 146),(187, 77, 253),(155, 22, 122),(218, 130, 77),(164, 102, 79),(43, 152, 125),(185, 124, 151),(95, 159, 238),(128, 89, 85),(228, 6, 60),(6, 41, 210),(11, 1, 133),(30, 96, 58),(230, 136, 109),(126, 45, 174),(164, 63, 165),(32, 111, 29),(232, 40, 70),(55, 31, 198),(148, 211, 129),(10, 186, 211),(181, 201, 94),(55, 35, 92),(129, 140, 233),(70, 250, 116),(61, 209, 152),(216, 21, 138),(100, 0, 176),(3, 42, 70),(151, 13, 44),(216, 102, 88),(125, 216, 93),(171, 236, 47),(253, 127, 103),(205, 137, 244),(193, 137, 224),(36, 152, 214),(17, 50, 238),(154, 165, 67),(114, 129, 60),(119, 24, 48),(73, 8, 110)]\n",
    "  \n",
    "  #plot each boxes\n",
    "  for box in boxes:\n",
    "    #add score in label if score=True\n",
    "    if score :\n",
    "      label = labels[int(box[-1])+1] + \" \" + str(round(100 * float(box[-2]),1)) + \"%\"\n",
    "    else :\n",
    "      label = labels[int(box[-1])+1]\n",
    "    #filter every box under conf threshold if conf threshold setted\n",
    "    if conf :\n",
    "      if box[-2] > conf:\n",
    "        color = colors[int(box[-1])]\n",
    "        box_label(image, box, label, color)\n",
    "    else:\n",
    "      color = colors[int(box[-1])]\n",
    "      box_label(image, box, label, color)\n",
    "\n",
    "  #show image\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "  try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "  except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "  if IN_COLAB:\n",
    "    cv2_imshow(image) #if used in Colab\n",
    "  else :\n",
    "    cv2.imshow(image) #if used in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_source = '../data/satellite_images_train_v1/satellite_predict_test_y.jpg'\n",
    "image = Image.open(image_source)\n",
    "image = np.asarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 416x640 (no detections), 163.9ms\n",
      "Speed: 0.5ms preprocess, 163.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "results_function = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_bboxes(image, results[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mboxes\u001b[39m.\u001b[39;49mboxes, conf\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[27], line 38\u001b[0m, in \u001b[0;36mplot_bboxes\u001b[0;34m(image, boxes, labels, colors, score, conf)\u001b[0m\n\u001b[1;32m     36\u001b[0m   cv2_imshow(image) \u001b[39m#if used in Colab\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39melse\u001b[39;00m :\n\u001b[0;32m---> 38\u001b[0m   cv2\u001b[39m.\u001b[39;49mimshow(image)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n"
     ]
    }
   ],
   "source": [
    "plot_bboxes(image, results[0].boxes.boxes, conf=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 416x640 67 landslide-paths, 108.8ms\n",
      "Speed: 0.4ms preprocess, 108.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# from PIL\n",
    "im1 = Image.open('../data/satellite_images_train_v1/satellite_predict_test_y.jpg')\n",
    "results = model.predict(source=im1, save=True)  # save plotted images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
